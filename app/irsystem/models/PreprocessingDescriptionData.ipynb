{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "from operator import itemgetter\n",
    "from nltk.stem import PorterStemmer\n",
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data-Set-Final.csv')\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    clean = re.compile('<.*?>')\n",
    "    cleantext = re.sub(clean, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Returns a list of words that make up the text.    \n",
    "    Params: {text: String}\n",
    "    Returns: List\n",
    "    \"\"\"\n",
    "    return list(filter(str.strip, list(map(lambda x: x, re.findall(r'[a-zA-Z]*', text)))))\n",
    "\n",
    "def stem(text):\n",
    "    stemmer=PorterStemmer()\n",
    "    stems = [stemmer.stem(w) for w in tokenize(text)]\n",
    "    return \" \".join(stems)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    text = cleanhtml(text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def preprocess(data):\n",
    "    for (index,value) in data['Summary'].items():\n",
    "        value = preprocess_text(value)\n",
    "        value = stem(value)\n",
    "        data.loc[index,'Summary'] = value\n",
    "    return data\n",
    "\n",
    "n_feats = 5000\n",
    "doc_by_vocab = np.empty([len(data), n_feats])\n",
    "\n",
    "def build_vectorizer(max_features, stop_words, max_df=0.8, min_df=10, norm='l2'):\n",
    "    \"\"\"Returns a TfidfVectorizer object with the above preprocessing properties.\n",
    "    \n",
    "    Params: {max_features: Integer,\n",
    "             max_df: Float,\n",
    "             min_df: Float,\n",
    "             norm: String,\n",
    "             stop_words: String}\n",
    "    Returns: TfidfVectorizer\n",
    "    \"\"\"\n",
    "    \n",
    "    result = TfidfVectorizer(max_features = max_features, stop_words = stop_words, max_df = max_df, min_df = min_df, norm = norm)\n",
    "    return result\n",
    "\n",
    "data = preprocess(data)\n",
    "tfidf_vec = build_vectorizer(n_feats, \"english\")\n",
    "doc_by_vocab = tfidf_vec.fit_transform([value for _,value in data['Summary'].items()]).toarray()\n",
    "index_to_vocab = {i:v for i, v in enumerate(tfidf_vec.get_feature_names())}\n",
    "movie_index_to_name = data['Title'].to_dict()\n",
    "movie_name_to_index = {v: k for k, v in movie_index_to_name.items()}\n",
    "num_movies = len(data)\n",
    "\n",
    "def get_sim(mov1, mov2, input_doc_mat, movie_name_to_index):\n",
    "    \"\"\"Returns a float giving the cosine similarity of \n",
    "       the two movie transcripts.\n",
    "    \n",
    "    Params: {mov1: String,\n",
    "             mov2: String,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_name_to_index: Dict}\n",
    "    Returns: Float (Cosine similarity of the two movie transcripts.)\n",
    "    \"\"\"\n",
    "    idx1 = movie_name_to_index[mov1]\n",
    "    idx2 = movie_name_to_index[mov2]\n",
    "    movie1 = input_doc_mat[idx1,]\n",
    "    movie2 = input_doc_mat[idx2,]\n",
    "    dot_product = np.dot(movie1, movie2)\n",
    "    return dot_product\n",
    "\n",
    "def build_movie_sims_cos(n_mov, movie_index_to_name, input_doc_mat, movie_name_to_index, input_get_sim_method):\n",
    "    \"\"\"Returns a movie_sims matrix of size (num_movies,num_movies) where for (i,j):\n",
    "        [i,j] should be the cosine similarity between the movie with index i and the movie with index j\n",
    "    \n",
    "    Params: {n_mov: Integer,\n",
    "             movie_index_to_name: Dict,\n",
    "             input_doc_mat: Numpy Array,\n",
    "             movie_name_to_index: Dict,\n",
    "             input_get_sim_method: Function}\n",
    "    Returns: Numpy Array\n",
    "    \"\"\"\n",
    "    result = np.zeros((n_mov, n_mov))\n",
    "    for i in range(n_mov):\n",
    "        for j in range(n_mov):\n",
    "            if i == j:\n",
    "                result[i,j] = 0\n",
    "            else:\n",
    "                mov1 = movie_index_to_name[i]\n",
    "                mov2 = movie_index_to_name[j]\n",
    "                result[i,j] = input_get_sim_method(mov1, mov2, input_doc_mat, movie_name_to_index)\n",
    "    \n",
    "            \n",
    "    return result\n",
    "\n",
    "movie_sims_cos = build_movie_sims_cos(num_movies, movie_index_to_name, doc_by_vocab, movie_name_to_index, get_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Drama_Title  Summary_Similarity  Genre_Similarity  \\\n",
      "667                     Stranger            0.432997               1.0   \n",
      "415          Sweet Savage Family            0.276500               1.0   \n",
      "722          The Queen of Office            0.237680               1.0   \n",
      "824           The Wedding Scheme            0.218926               1.0   \n",
      "242        Bad Thief, Good Thief            0.212300               1.0   \n",
      "312                  Be Positive            0.212232               1.0   \n",
      "428             You Will Love Me            0.210892               1.0   \n",
      "498                    The Lover            0.208423               1.0   \n",
      "333  Cinderella and Four Knights            0.207837               1.0   \n",
      "32              The Best Chicken            0.205444               1.0   \n",
      "\n",
      "     Network_Similarity     Total  \n",
      "667                   0  1.432997  \n",
      "415                   0  1.276500  \n",
      "722                   0  1.237680  \n",
      "824                   0  1.218926  \n",
      "242                   0  1.212300  \n",
      "312                   0  1.212232  \n",
      "428                   0  1.210892  \n",
      "498                   0  1.208423  \n",
      "333                   0  1.207837  \n",
      "32                    0  1.205444  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def best_match(n_mov, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, dramas_enjoyed, dramas_disliked, preferred_genres, preferred_network, num_results):\n",
    "    feature_list = ['Summary_Similarity', 'Genre_Similarity', 'Network_Similarity', 'Total']\n",
    "    result = pd.DataFrame(0, index=np.arange(n_mov), columns=feature_list)\n",
    "    genres = set()\n",
    "    preferred_genres = [preprocess_text(value) for value in preferred_genres]\n",
    "    genres.update(preferred_genres)\n",
    "    for drama in dramas_enjoyed:\n",
    "        if drama in movie_name_to_index.keys():\n",
    "            index = movie_name_to_index[drama]\n",
    "            sim = movie_sims_cos[index,:]\n",
    "            result['Summary_Similarity']+= pd.Series(sim)\n",
    "            \n",
    "    for drama in dramas_disliked:\n",
    "        if drama in movie_name_to_index.keys():\n",
    "            index = movie_name_to_index[drama]\n",
    "            sim = movie_sims_cos[index,:]\n",
    "            result['Summary_Similarity']-= pd.Series(sim)\n",
    "            \n",
    "    for index, value in data.iterrows():\n",
    "        gen = str(value['Genre'])\n",
    "        gen = preprocess_text(gen)\n",
    "        drama_genres = set()\n",
    "        drama_genres.update(gen.split())\n",
    "        result.loc[index,'Genre_Similarity'] = len(genres.intersection(drama_genres))/len(genres.union(drama_genres))\n",
    "        if preferred_network == data.iloc[index]['Network']:\n",
    "            result['Network_Similarity']+=1\n",
    "    result['Total'] = result.sum(axis = 1)\n",
    "    result = result.sort_values(by='Total', ascending=False)\n",
    "    result = result[:num_results]\n",
    "    indices =  result.index.tolist()\n",
    "    best_dramas = pd.Series([movie_index_to_name[index] for index in indices],index = result.index)\n",
    "    result.insert(loc=0, column='Drama_Title', value=best_dramas)\n",
    "    result.reset_index()\n",
    "    return result\n",
    "\n",
    "best = best_match(num_movies, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, [\"Doctor Stranger\",\"Doctors\",\"Emergency Couple\"], ['Man x Man', 'Black'], [\"Romance\",\"comedy\"], [], 10)      \n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display (n_mov, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, dramas_enjoyed, dramas_disliked, preferred_genres, preferred_network, num_results):\n",
    "    dramas_enjoyed = dramas_enjoyed.split(',')\n",
    "    dramas_disliked = dramas_disliked.split(',')\n",
    "    preferred_genres = preferred_genres.split(',')\n",
    "    preferred_network = preferred_network.split(',')\n",
    "    best = best_match(n_mov, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, dramas_enjoyed, dramas_disliked, preferred_genres, preferred_network, num_results)\n",
    "    title = list(zip(best['Drama_Title'], best[\"Total\"]))\n",
    "    final = [\"Drama Titles: {}\".format(final_title[0]) + \"            \" +\"Total Similarity {}\".format(final_title[1]) for final_title in title]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama Titles: Stranger            Total Similarity 1.3863795413185234',\n",
       " 'Drama Titles: Sweet Savage Family            Total Similarity 1.2242656833768708',\n",
       " 'Drama Titles: Bad Thief, Good Thief            Total Similarity 1.2040638364752747',\n",
       " 'Drama Titles: Spy Myung Wol / Myung Wol the Spy            Total Similarity 1.1780086800746379',\n",
       " 'Drama Titles: Pool Ha-woo-seu / Full House            Total Similarity 1.1375280929768496',\n",
       " 'Drama Titles: The Best Chicken            Total Similarity 1.1293732985685292',\n",
       " 'Drama Titles: Dating Agency: Cyrano            Total Similarity 1.1270186211312088',\n",
       " 'Drama Titles: Yeol A-hob Soon-jeong / Pure 19            Total Similarity 1.1200953202507156',\n",
       " 'Drama Titles: Divorce Lawyer in Love            Total Similarity 1.118864293072026',\n",
       " 'Drama Titles: The Cravings (Season 2)            Total Similarity 1.1086291251241043']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(num_movies, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, \"Doctor Stranger, Doctors, Emergency Couple\", 'Black', \"Romance, comedy\", '', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from . import *  \n",
    "from helpers import *\n",
    "from helpers import NumpyEncoder as NumpyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'route' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-72f31bc5c2e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0menjoyed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"enjoyed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdisliked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'disliked'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprefered_genres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prefered_genres'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'route' is not defined"
     ]
    }
   ],
   "source": [
    "route('/', methods=['GET'])\n",
    "def search():\n",
    "    enjoyed = request.args.get(\"enjoyed\")\n",
    "    disliked = request.args.get('disliked')\n",
    "    prefered_genres = request.args.get('prefered_genres')\n",
    "    prefered_networks = request.args.get('prefered_networks')\n",
    "\n",
    "    if not enjoyed and not prefered_genres:\n",
    "        output = []\n",
    "        output_message = ''\n",
    "    else:\n",
    "        output_message = \"You searched: \" + enjoyed\n",
    "        output = display(num_movies, movie_sims_cos, data, movie_index_to_name, movie_name_to_index, enjoyed, disliked, prefered_genres, prefered_networks, 10)\n",
    "\n",
    "    return render_template('search.html', name=project_name, netid=net_id, output_message=output_message, output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
